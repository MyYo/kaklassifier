{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import preprocess\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, _ = preprocess.load_data()b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 0s 124us/step - loss: 1.6171 - acc: 0.3158\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 111us/step - loss: 1.6165 - acc: 0.3158\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 126us/step - loss: 1.6160 - acc: 0.3158\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 137us/step - loss: 1.6156 - acc: 0.3158\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 141us/step - loss: 1.6152 - acc: 0.3158\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 139us/step - loss: 1.6148 - acc: 0.3158\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 146us/step - loss: 1.6143 - acc: 0.3158\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 152us/step - loss: 1.6139 - acc: 0.3158\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 141us/step - loss: 1.6136 - acc: 0.3158\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 146us/step - loss: 1.6133 - acc: 0.3158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.10098772, 0.08789615, 0.09316479, 0.09847596, 0.09131532,\n",
       "        0.13312249, 0.10090231, 0.09219842, 0.10623385, 0.09570301],\n",
       "       [0.09298928, 0.0930362 , 0.10205667, 0.09965488, 0.10344619,\n",
       "        0.10997295, 0.11154244, 0.09987761, 0.09440677, 0.09301698],\n",
       "       [0.09690991, 0.08129881, 0.11795869, 0.09478121, 0.09461122,\n",
       "        0.11056446, 0.10494071, 0.09546984, 0.10309116, 0.10037404],\n",
       "       [0.09527439, 0.1010366 , 0.10203846, 0.10630587, 0.09473164,\n",
       "        0.10134435, 0.09324486, 0.10265826, 0.10499414, 0.09837142],\n",
       "       [0.10659277, 0.09215012, 0.10242855, 0.11223736, 0.10257724,\n",
       "        0.0976246 , 0.10086746, 0.09241924, 0.08436554, 0.10873719],\n",
       "       [0.10678275, 0.09731163, 0.09972386, 0.10672099, 0.0917005 ,\n",
       "        0.11518109, 0.10041694, 0.09499632, 0.10030548, 0.08686046],\n",
       "       [0.08444229, 0.09708744, 0.08772175, 0.11379495, 0.10521723,\n",
       "        0.10027409, 0.10637033, 0.10469545, 0.10178199, 0.09861449],\n",
       "       [0.09829123, 0.10001915, 0.10057446, 0.09140395, 0.11086302,\n",
       "        0.10609594, 0.08905365, 0.09540042, 0.11939102, 0.08890723],\n",
       "       [0.08097725, 0.07821034, 0.11411236, 0.12074777, 0.0927006 ,\n",
       "        0.10391727, 0.09095281, 0.12284639, 0.09418397, 0.10135122],\n",
       "       [0.06377278, 0.08165213, 0.11145985, 0.07959095, 0.0723839 ,\n",
       "        0.15939322, 0.10034297, 0.11245211, 0.09701911, 0.12193304],\n",
       "       [0.07790776, 0.09992097, 0.11893831, 0.08977126, 0.07954033,\n",
       "        0.10429709, 0.09484907, 0.09916408, 0.14070147, 0.09490956],\n",
       "       [0.06360712, 0.09613573, 0.07362082, 0.11115184, 0.15988304,\n",
       "        0.03986777, 0.15621117, 0.07639227, 0.10760666, 0.11552364],\n",
       "       [0.10296337, 0.09638754, 0.10427695, 0.09692606, 0.09234934,\n",
       "        0.10816506, 0.09420121, 0.09792222, 0.10214009, 0.10466819],\n",
       "       [0.09616275, 0.09281545, 0.09612175, 0.09782077, 0.09843822,\n",
       "        0.09387639, 0.10518362, 0.10032059, 0.10605519, 0.11320522],\n",
       "       [0.0883822 , 0.09804967, 0.0906318 , 0.10139044, 0.10646588,\n",
       "        0.09943754, 0.08237262, 0.10937648, 0.12385873, 0.10003459],\n",
       "       [0.14072527, 0.13908133, 0.14106229, 0.06132716, 0.07940362,\n",
       "        0.06263938, 0.08235131, 0.13203809, 0.08695302, 0.07441856],\n",
       "       [0.11354072, 0.07455934, 0.0936677 , 0.10726944, 0.09367075,\n",
       "        0.1244202 , 0.11331839, 0.09643853, 0.08306886, 0.10004613],\n",
       "       [0.09171335, 0.14998958, 0.07441399, 0.09857589, 0.0918491 ,\n",
       "        0.10542289, 0.10363795, 0.07800104, 0.07944442, 0.12695181],\n",
       "       [0.09603178, 0.10798548, 0.07494413, 0.09131598, 0.13261487,\n",
       "        0.08345955, 0.11423171, 0.0750164 , 0.10622717, 0.11817292],\n",
       "       [0.07638756, 0.1365879 , 0.07214963, 0.08321462, 0.10847239,\n",
       "        0.089684  , 0.11516767, 0.06163683, 0.1416305 , 0.11506882],\n",
       "       [0.11768095, 0.10515395, 0.08321074, 0.08834886, 0.08679035,\n",
       "        0.08894372, 0.095495  , 0.10104932, 0.13019016, 0.10313699],\n",
       "       [0.07041539, 0.11054959, 0.13546899, 0.10560545, 0.11246206,\n",
       "        0.11989093, 0.08345155, 0.06799101, 0.08501201, 0.10915307],\n",
       "       [0.10810387, 0.0856107 , 0.09391159, 0.09991813, 0.10861987,\n",
       "        0.07955707, 0.12036466, 0.10942556, 0.09083632, 0.10365226],\n",
       "       [0.09193138, 0.09255043, 0.09864219, 0.08991126, 0.09343926,\n",
       "        0.12086628, 0.09945022, 0.10909738, 0.11656794, 0.0875436 ],\n",
       "       [0.07871252, 0.0992014 , 0.08473247, 0.09813411, 0.09797037,\n",
       "        0.10125207, 0.10062801, 0.10881861, 0.12217705, 0.10837343],\n",
       "       [0.1204613 , 0.08431976, 0.11233883, 0.10574008, 0.0984126 ,\n",
       "        0.08786567, 0.11232009, 0.10069977, 0.09186331, 0.08597854],\n",
       "       [0.08980713, 0.10057415, 0.11729531, 0.09298889, 0.09443737,\n",
       "        0.10792995, 0.08674139, 0.0990751 , 0.09607759, 0.11507306],\n",
       "       [0.09564421, 0.06901883, 0.09305737, 0.08116496, 0.09222363,\n",
       "        0.09002267, 0.11109344, 0.09834213, 0.16454847, 0.10488431],\n",
       "       [0.10487519, 0.10787193, 0.10128577, 0.12090244, 0.08647729,\n",
       "        0.10062925, 0.08233223, 0.10494027, 0.08961551, 0.10107011],\n",
       "       [0.08300254, 0.10438035, 0.10287265, 0.08442587, 0.09489354,\n",
       "        0.09295241, 0.08700813, 0.12038193, 0.13558492, 0.09449755],\n",
       "       [0.10852935, 0.13024639, 0.06561281, 0.10812359, 0.08687901,\n",
       "        0.0879955 , 0.07908332, 0.11593445, 0.11320765, 0.10438792],\n",
       "       [0.09735848, 0.10562696, 0.11106358, 0.09770064, 0.11180405,\n",
       "        0.11342715, 0.10193662, 0.09013336, 0.08837937, 0.08256978],\n",
       "       [0.08650682, 0.10178393, 0.10088311, 0.09101671, 0.10611759,\n",
       "        0.10655983, 0.10619967, 0.1064743 , 0.09293713, 0.10152096],\n",
       "       [0.09734629, 0.09314165, 0.08821382, 0.10796178, 0.10858288,\n",
       "        0.09478084, 0.09858444, 0.10362261, 0.10846312, 0.09930257],\n",
       "       [0.11317963, 0.10974648, 0.12201028, 0.08747816, 0.09330709,\n",
       "        0.11576398, 0.06153773, 0.10569556, 0.10458934, 0.0866918 ],\n",
       "       [0.11892759, 0.08907849, 0.11935354, 0.07787951, 0.10929032,\n",
       "        0.10771931, 0.09356793, 0.09329132, 0.07761607, 0.11327593],\n",
       "       [0.11742283, 0.08298406, 0.09777427, 0.13011968, 0.10147652,\n",
       "        0.08732288, 0.07674784, 0.12623999, 0.1114625 , 0.06844939],\n",
       "       [0.09110025, 0.0776824 , 0.12205417, 0.12750246, 0.09704725,\n",
       "        0.09566557, 0.08955786, 0.10856858, 0.10233859, 0.0884828 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.fit(X, y, epochs=10,\n",
    "#                   validation_data=(X_val, y_val)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 10)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate training loss\n",
    "y_bar = model.predict(X)\n",
    "# error = np.sum(y - y_bar)\n",
    "print(y_bar.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaklassifier-env",
   "language": "python",
   "name": "kaklassifier-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
